{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jupyter_black\n",
    "\n",
    "jupyter_black.load()  # Python linter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatically provide the LLM an MCP Tool (during runtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "We will use the `pydantic-ai-slim[mcp]` package for interacting with the MCP Servers \n",
    "\n",
    "- Install it with: `pip install baml-agents[pydantic-mcp]`\n",
    "\n",
    "## Let's get started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's create the BAML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class ToolCall {\n",
      "    @@dynamic\n",
      "}\n",
      "\n",
      "function UseTool(goal: string, output_format_prefix: string) -> ToolCall {\n",
      "    client Default\n",
      "    prompt #\"\n",
      "        Solve: {{ goal }}\n",
      "\n",
      "        {{ ctx.output_format(prefix=output_format_prefix, or_splitter=\" OR \")}}\n",
      "    \"#\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%cat ../baml_src/02_use_tool.baml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let's add the MCP Server config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_ai.mcp import MCPServerStdio\n",
    "\n",
    "from baml_agents.deprecated.pydantic_mcp import McpServers\n",
    "from baml_agents.utils import get_payload\n",
    "from baml_client.async_client import b\n",
    "from baml_client.type_builder import TypeBuilder\n",
    "\n",
    "server_with_calculator_tool = McpServers(\n",
    "    [\n",
    "        MCPServerStdio(\n",
    "            command=\"python\",\n",
    "            args=[\"-m\", \"mcp-server-calculator\"],\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatically fill the LLM prompt with the available MCP Tools from the MCP Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[system]\n",
       "Solve: Multiply all numbers between 10 and 15\n",
       "\n",
       "What are the next steps?\n",
       "\n",
       "Answer in JSON format with one or multiple of the following intents:\n",
       "\n",
       "{\n",
       "  intents: [\n",
       "    {\n",
       "      // Calculates/evaluates the given expression.\n",
       "      intent: \"calculate\",\n",
       "      expression: string,\n",
       "    }\n",
       "  ],\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "async with server_with_calculator_tool as server:\n",
    "    # Add MCP tools to the BAML structured output schema\n",
    "    tb, tool_runner, p = await server.build_tool_types(\n",
    "        tb := TypeBuilder(),\n",
    "        output_class=tb.ToolCall,\n",
    "        tools=await server.list_tools(),\n",
    "    )\n",
    "\n",
    "    # View prompt\n",
    "    goal = \"Multiply all numbers between 10 and 15\"\n",
    "    request = await b.request.UseTool(goal, p, baml_options={\"tb\": tb})\n",
    "    print(get_payload(request))\n",
    "\n",
    "    # LLM chooses the tools\n",
    "    result = await b.UseTool(goal, p, baml_options={\"tb\": tb})\n",
    "\n",
    "    # Run the tools\n",
    "    tool_results = await tool_runner.run(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the LLM-chosen arguments before calling the MCP Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolCall(intents=[{'intent': 'calculate', 'expression': '11 * 12 * 13 * 14'}])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's call the MCP Tool and show the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CallToolResult(meta=None, content=[TextContent(type='text', text='24024', annotations=None)], isError=False)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
